{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "\n",
    "[I. Load dữ liệu](#I.-Load-dữ-liệu)<br>\n",
    "[1.1 Understand Data](#1.1-Understand-Data)<br>\n",
    "[1.2 Prepare Data](#1.2-Prepare-Data)<br>\n",
    "[1.3 Preprocessing data](#1.3-Preprocessing-data)<br>\n",
    "\n",
    "[II. Build model](#II.-Build-model)<br>\n",
    "[2.1 Baseline model](#2.1-Baseline-model)<br>\n",
    "[2.2 Evaluation](#2.2-Evaluation)<br>\n",
    "\n",
    "[III. Conclusions](#III.-Conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Load dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Understand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu sắp sử dụng có **18** cuốn tiểu thuyết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen', 'bible', 'blake', 'bryant', 'burgess', 'carroll', 'chesterton', 'edgeworth', 'melville', 'milton', 'shakespeare', 'whitman']\n",
      "Có 12 tác giả khác nhau.\n"
     ]
    }
   ],
   "source": [
    "lis = [] # initial list\n",
    "for i in gutenberg.fileids():\n",
    "    author_name = i.split('-')[0] # Tên tác giả\n",
    "    if author_name not in lis:\n",
    "        lis.append(author_name)\n",
    "print(lis)\n",
    "print('Có', len(lis), 'tác giả khác nhau.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Đọc thử một tác phẩm (Alice in Wonderland của Lewis Carroll)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I. Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversatio\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.raw('carroll-alice.txt')[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dạng đọc này chưa phải là plain text (cho người đọc) vì vẫn còn các dòng lệnh như \\n (newline)\n",
    "- Các từ dạng thuần văn nên độ nhiễu sẽ cao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thống kê đặc tính văn bản của 18 cuốn tiểu thuyết trên:**\n",
    "- Cột 1 : số từ trong tác phẩm\n",
    "- Cột 2 : số câu trong tác phẩm\n",
    "- Cột 3 : lượng từ vựng trong tác phẩm\n",
    "- Cột 4 : tên tác phẩm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192427 7752 7811 austen-emma.txt\n",
      "98171 3747 6132 austen-persuasion.txt\n",
      "141576 4999 6833 austen-sense.txt\n",
      "1010654 30103 13769 bible-kjv.txt\n",
      "8354 438 1820 blake-poems.txt\n",
      "55563 2863 4420 bryant-stories.txt\n",
      "18963 1054 1764 burgess-busterbrown.txt\n",
      "34110 1703 3016 carroll-alice.txt\n",
      "96996 4779 8947 chesterton-ball.txt\n",
      "86063 3806 8299 chesterton-brown.txt\n",
      "69213 3742 6807 chesterton-thursday.txt\n",
      "210663 10230 9593 edgeworth-parents.txt\n",
      "260819 10059 19317 melville-moby_dick.txt\n",
      "96825 1851 10751 milton-paradise.txt\n",
      "25833 2163 3560 shakespeare-caesar.txt\n",
      "37360 3106 5447 shakespeare-hamlet.txt\n",
      "23140 1907 4017 shakespeare-macbeth.txt\n",
      "154883 4250 14329 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "for fileid in gutenberg.fileids():\n",
    "    num_word = len(gutenberg.words(fileid)) # số từ\n",
    "    num_sent = len(gutenberg.sents(fileid)) # số câu\n",
    "    num_vocab = len(set(gutenberg.words(fileid))) # lượng từ vựng\n",
    "    print(num_word, num_sent, num_vocab, fileid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cách lấy list từng đoạn văn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']']], [['CHAPTER', 'I', '.'], ['Down', 'the', 'Rabbit', '-', 'Hole']], ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.paras('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Mouse', 'only', 'growled', 'in', 'reply', '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.paras('carroll-alice.txt')[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Những `paras` này không phải là những câu văn mà là đoạn văn đã được lọc ra. Chứng minh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gutenberg.paras('carroll-alice.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Độ dài của paras trong cuốn Alice in Wonderland được đo là 817 nhưng với phần thống kê ở trước là có **1703** câu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ý tưởng**: lập một dataframe với **2** cột, một là đoạn văn và một là tên tác giả."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "from itertools import chain\n",
    "author_column = []\n",
    "paragraphs_column = []\n",
    "for fileid in gutenberg.fileids():\n",
    "    author_name = fileid.split('-')[0] # Tên tác giả\n",
    "    work = gutenberg.paras(fileid) # nhiều đoạn văn trong fileid đó\n",
    "    for paragraph in work:\n",
    "        author_column.append(author_name) # mỗi đoạn tương ứng với tên của tác giả (bao nhiêu đoạn bấy nhiêu lần tên tác giả)\n",
    "        paragraph = list(chain.from_iterable(paragraph)) # để bỏ bớt một list chồng\n",
    "        paragraphs_column.append(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47887"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(author_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47887"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok vậy là ta có **2 cột**. Và biết được trong 18 cuốn tiểu thuyết ở trên thì có tổng cộng 47887 đoạn văn. Giờ ta sẽ lập dataframe cho **2 cột** này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[, Emma, by, Jane, Austen, 1816, ]]</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VOLUME, I]</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CHAPTER, I]</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Emma, Woodhouse, ,, handsome, ,, clever, ,, a...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[She, was, the, youngest, of, the, two, daught...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   label\n",
       "0               [[, Emma, by, Jane, Austen, 1816, ]]  austen\n",
       "1                                        [VOLUME, I]  austen\n",
       "2                                       [CHAPTER, I]  austen\n",
       "3  [Emma, Woodhouse, ,, handsome, ,, clever, ,, a...  austen\n",
       "4  [She, was, the, youngest, of, the, two, daught...  austen"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.DataFrame({'sentence': paragraphs_column,\n",
    "                         'label': author_column})\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['sentence'][0] # xem câu đầu tiên trong cột 'sentence'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nối các từ thành lại 1 câu\n",
    "- Giờ ta cần xử lý để bỏ những stop words (như but, and, than...)\n",
    "- Bỏ những dấu , . ! ?\n",
    "- Biến chữ hoa thành chữ thường"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nối các từ lại thành câu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['sentence'] = [' '.join(sentence) for sentence in dataframe['sentence']] # list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Emma by Jane Austen 1816 ]</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VOLUME I</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHAPTER I</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma Woodhouse , handsome , clever , and rich ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She was the youngest of the two daughters of a...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   label\n",
       "0                       [ Emma by Jane Austen 1816 ]  austen\n",
       "1                                           VOLUME I  austen\n",
       "2                                          CHAPTER I  austen\n",
       "3  Emma Woodhouse , handsome , clever , and rich ...  austen\n",
       "4  She was the youngest of the two daughters of a...  austen"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tiền xử lý**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "#from gensim.parsing.preprocessing import strip_tags # bỏ tag name \n",
    "from gensim.parsing.preprocessing import remove_stopwords # bỏ stop words\n",
    "from gensim.parsing.preprocessing import strip_punctuation # bỏ dấu\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_punctuation, remove_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý trong 'CUSTOM_FILTERS' ở đây ta chỉ muốn biến chữ hoa về chữ thường, bỏ hệ thống dấu trong câu văn, và bỏ stop words, bỏ những đoạn có dưới 3 từ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['sentence'] = [preprocess_string(sentence, CUSTOM_FILTERS) for sentence in dataframe['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[emma, jane, austen, 1816]</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[volume]</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[chapter]</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[emma, woodhouse, handsome, clever, rich, comf...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[youngest, daughters, affectionate, indulgent,...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   label\n",
       "0                         [emma, jane, austen, 1816]  austen\n",
       "1                                           [volume]  austen\n",
       "2                                          [chapter]  austen\n",
       "3  [emma, woodhouse, handsome, clever, rich, comf...  austen\n",
       "4  [youngest, daughters, affectionate, indulgent,...  austen"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thấy có những đoạn văn có lượng từ rất nhỏ như ở vị trí hàng 0,1,2. Ta drop những hàng có độ dài đoạn văn nhỏ hơn **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [] # tìm index của các element có độ dài dưới 5\n",
    "for i in range(len(dataframe)):\n",
    "    n= dataframe['sentence'].iloc[i]\n",
    "    if len(n) < 5:\n",
    "        lis.append(i)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[emma, woodhouse, handsome, clever, rich, comf...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[youngest, daughters, affectionate, indulgent,...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[sixteen, years, miss, taylor, mr, woodhouse, ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[real, evils, emma, s, situation, power, havin...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[sorrow, came, gentle, sorrow, shape, disagree...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   label\n",
       "3  [emma, woodhouse, handsome, clever, rich, comf...  austen\n",
       "4  [youngest, daughters, affectionate, indulgent,...  austen\n",
       "5  [sixteen, years, miss, taylor, mr, woodhouse, ...  austen\n",
       "6  [real, evils, emma, s, situation, power, havin...  austen\n",
       "7  [sorrow, came, gentle, sorrow, shape, disagree...  austen"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = dataframe.drop(index=lis) # drop những hàng đó đi\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bible          24383\n",
       "austen          4574\n",
       "chesterton      3506\n",
       "edgeworth       3182\n",
       "melville        2328\n",
       "whitman         2065\n",
       "shakespeare     1598\n",
       "bryant           970\n",
       "carroll          673\n",
       "burgess          225\n",
       "blake            224\n",
       "milton            16\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu lúc này khá imbalance. Dữ liệu imbalance không hẳn là một vấn đề lớn trong deep learning nhưng ta có thể suy tính bằng một cách khác như dùng thuật toán không bị ảnh hưởng của sự mất cân bằng dữ liệu như: random forest, logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dùng Word2vec để vector hóa từng chữ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43744"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(dataframe['sentence'], size=150, window=5, min_count=1, seed=0, compute_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Size là số chiều khi embedding, mặc định là 100\n",
    "- Window là khoảng cách tối đa giữa từ mục tiêu và các từ xung quanh nó\n",
    "- Min count là số lượng đếm tối thiểu các từ khi training, từ có số lượng nhỏ hơn sẽ bị lờ đi. Mặc định là 5\n",
    "- Workers là số lượng chia cắt trong khi training. Mặc định là 3\n",
    "- sg là thuật toán train, 'cbow' là 0, 'skip gram' là 1. Mặc định CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9140472, 9609340)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(dataframe['sentence'], total_examples=len(dataframe['sentence']), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest training loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "print('Latest training loss: %.2f'%model.get_latest_training_loss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử xem những từ gần với từ 'alice' trong vocab của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hatter', 0.8703389167785645),\n",
       " ('gryphon', 0.8376980423927307),\n",
       " ('duchess', 0.8369855284690857),\n",
       " ('dormouse', 0.8337677717208862),\n",
       " ('laughing', 0.8059630393981934),\n",
       " ('smiling', 0.7840709686279297)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('alice', topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_embedding = []\n",
    "\n",
    "for paragraph in dataframe['sentence']:\n",
    "    paragraph_embedding = []\n",
    "    for word in paragraph:\n",
    "        word_embedding = model.wv.get_vector(word)\n",
    "        paragraph_embedding.append(word_embedding)\n",
    "    paragraphs_embedding.append(paragraph_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nối các vector lại trong đoạn văn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# trim and pad embeddign paragraph\n",
    "from keras.preprocessing import sequence\n",
    "paragraphs_embedding = sequence.pad_sequences(paragraphs_embedding, maxlen=130, padding='post', truncating='post', value=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- khong noi vector: np.mean(paragraph_embedding)\n",
    "- kich thuoc w2v co dinh 150, nen mean cua cac vector co chieu giong nhau\n",
    "- dung cac thuat toan khac nhu regression, random forest\n",
    "- random forest solve duoc cho imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('wonderland').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chiều vector của các từ trong vocab là như nhau. Như đã set trong gensim là **150**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43744, 130, 150)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43744, 12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(dataframe['label'])\n",
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen', 'bible', 'blake', 'bryant', 'burgess', 'carroll', 'chesterton', 'edgeworth', 'melville', 'milton', 'shakespeare', 'whitman']\n"
     ]
    }
   ],
   "source": [
    "feature_name= list(one_hot.columns)\n",
    "print(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df\n",
    "y = one_hot\n",
    "X = paragraphs_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hold out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34995, 130, 150)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for sequence classification\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\OS\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\OS\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 130, 150)          67650     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 130, 100)          45100     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               1950150   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1812      \n",
      "=================================================================\n",
      "Total params: 2,064,712\n",
      "Trainable params: 2,064,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# CONVOLUTIONAL NEURAL NETWORK\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(150, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "cnn.add(Conv1D(100, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dropout(0.5,seed=0))\n",
    "cnn.add(Dense(150))\n",
    "cnn.add(Dense(12, activation='softmax'))\n",
    "# compile model\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\OS\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "34995/34995 [==============================] - 9s 262us/step - loss: 0.5487 - acc: 0.8144\n",
      "Epoch 2/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.3373 - acc: 0.8859\n",
      "Epoch 3/30\n",
      "34995/34995 [==============================] - 7s 186us/step - loss: 0.2830 - acc: 0.9038\n",
      "Epoch 4/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.2444 - acc: 0.9151\n",
      "Epoch 5/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.2156 - acc: 0.9244\n",
      "Epoch 6/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.1890 - acc: 0.9333\n",
      "Epoch 7/30\n",
      "34995/34995 [==============================] - 7s 186us/step - loss: 0.1712 - acc: 0.9412\n",
      "Epoch 8/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.1592 - acc: 0.9442\n",
      "Epoch 9/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.1470 - acc: 0.9503\n",
      "Epoch 10/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.1331 - acc: 0.9543\n",
      "Epoch 11/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.1230 - acc: 0.9565\n",
      "Epoch 12/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.1184 - acc: 0.9588\n",
      "Epoch 13/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.1107 - acc: 0.9618\n",
      "Epoch 14/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.1061 - acc: 0.9636\n",
      "Epoch 15/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.1008 - acc: 0.9652\n",
      "Epoch 16/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.0919 - acc: 0.9686\n",
      "Epoch 17/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.0870 - acc: 0.9702\n",
      "Epoch 18/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.0884 - acc: 0.9702\n",
      "Epoch 19/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.0913 - acc: 0.9693\n",
      "Epoch 20/30\n",
      "34995/34995 [==============================] - 7s 189us/step - loss: 0.0866 - acc: 0.9710\n",
      "Epoch 21/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.0774 - acc: 0.9740\n",
      "Epoch 22/30\n",
      "34995/34995 [==============================] - 7s 187us/step - loss: 0.0752 - acc: 0.9750\n",
      "Epoch 23/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.0755 - acc: 0.9759 0s - loss: 0.0757 - acc: 0.97\n",
      "Epoch 24/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.0657 - acc: 0.9767\n",
      "Epoch 25/30\n",
      "34995/34995 [==============================] - 7s 189us/step - loss: 0.0653 - acc: 0.9780\n",
      "Epoch 26/30\n",
      "34995/34995 [==============================] - 7s 189us/step - loss: 0.0663 - acc: 0.9784\n",
      "Epoch 27/30\n",
      "34995/34995 [==============================] - 7s 189us/step - loss: 0.0633 - acc: 0.9787\n",
      "Epoch 28/30\n",
      "34995/34995 [==============================] - 7s 189us/step - loss: 0.0653 - acc: 0.9784\n",
      "Epoch 29/30\n",
      "34995/34995 [==============================] - 7s 188us/step - loss: 0.0672 - acc: 0.9768\n",
      "Epoch 30/30\n",
      "34995/34995 [==============================] - 7s 189us/step - loss: 0.0622 - acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27151a03278>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('D:/CBD robotics course/Assignment/Assignment 09/trained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.42%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá qua classification_report để có cái nhìn insight hơn về kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted_y = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ta có `predicted_y` là một numpy array, ta cần `np.argmax()` để tìm ra index thực của (cũng là nhãn) của dữ liệu\n",
    "- Trong khi đầu vào y của chúng ta là một dataframe nên `y_test` cũng là một dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OS\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      austen       0.93      0.88      0.91       953\n",
      "       bible       1.00      1.00      1.00      4795\n",
      "       blake       0.54      0.17      0.26        41\n",
      "      bryant       0.60      0.56      0.58       199\n",
      "     burgess       1.00      0.76      0.86        45\n",
      "     carroll       0.85      0.62      0.72       143\n",
      "  chesterton       0.78      0.77      0.78       715\n",
      "   edgeworth       0.73      0.75      0.74       624\n",
      "    melville       0.75      0.78      0.77       473\n",
      "      milton       0.00      0.00      0.00         3\n",
      " shakespeare       0.96      0.86      0.91       339\n",
      "     whitman       0.63      0.85      0.73       419\n",
      "\n",
      "    accuracy                           0.90      8749\n",
      "   macro avg       0.73      0.67      0.69      8749\n",
      "weighted avg       0.91      0.90      0.90      8749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OS\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "feature_name= list(one_hot.columns) # list các nhãn là chữ\n",
    "y_pred = [np.argmax(i) for i in predicted_y] # Tìm argmax\n",
    "y_pred_label = [feature_name[i] for i in y_pred] # Biến list các nhãn này về chữ\n",
    "\n",
    "y_true_label = [np.argmax(y_test.iloc[i]) for i in range(y_test.shape[0])] # np.argmax(y_test.iloc[i] trả về\n",
    "                                                                           # column name trong dataframe\n",
    "# classification report\n",
    "print(classification_report(y_true_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>austen</th>\n",
       "      <th>bible</th>\n",
       "      <th>blake</th>\n",
       "      <th>bryant</th>\n",
       "      <th>burgess</th>\n",
       "      <th>carroll</th>\n",
       "      <th>chesterton</th>\n",
       "      <th>edgeworth</th>\n",
       "      <th>melville</th>\n",
       "      <th>milton</th>\n",
       "      <th>shakespeare</th>\n",
       "      <th>whitman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19067</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13207</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       austen  bible  blake  bryant  burgess  carroll  chesterton  edgeworth  \\\n",
       "6219        0      1      0       0        0        0           0          0   \n",
       "8978        0      1      0       0        0        0           0          0   \n",
       "19067       0      1      0       0        0        0           0          0   \n",
       "22999       0      1      0       0        0        0           0          0   \n",
       "13207       0      1      0       0        0        0           0          0   \n",
       "\n",
       "       melville  milton  shakespeare  whitman  \n",
       "6219          0       0            0        0  \n",
       "8978          0       0            0        0  \n",
       "19067         0       0            0        0  \n",
       "22999         0       0            0        0  \n",
       "13207         0       0            0        0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "austen         0\n",
       "bible          1\n",
       "blake          0\n",
       "bryant         0\n",
       "burgess        0\n",
       "carroll        0\n",
       "chesterton     0\n",
       "edgeworth      0\n",
       "melville       0\n",
       "milton         0\n",
       "shakespeare    0\n",
       "whitman        0\n",
       "Name: 6219, dtype: uint8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy mô hình phân loại rất tệ với tác giả milton, blake. Ta mở xem thử những tác phẩm của tác giả này là về thể loại gì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Poems by William Blake 1789]\n",
      "\n",
      " \n",
      "SONGS OF INNOCENCE AND OF EXPERIENCE\n",
      "and THE BOOK of THEL\n",
      "\n",
      "\n",
      " SONGS OF INNOCENCE\n",
      " \n",
      " \n",
      " INTRODUCTION\n",
      " \n",
      " Piping down the valleys wild,\n",
      "   Piping songs of pleasant glee,\n",
      " On a cloud I saw a child,\n",
      "   And he laughing said to me:\n",
      " \n",
      " \"Pipe a song about a Lamb!\"\n",
      "   So I piped\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.raw('blake-poems.txt')[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Paradise Lost by John Milton 1667] \n",
      " \n",
      " \n",
      "Book I \n",
      " \n",
      " \n",
      "Of Man's first disobedience, and the fruit \n",
      "Of that forbidden tree whose mortal taste \n",
      "Brought death into the World, and all our woe, \n",
      "With loss of Eden, till one greater Man \n",
      "Restore us, and regain the blissful seat, \n",
      "Sing, Heavenly Muse, that, o\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.raw('milton-paradise.txt')[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vậy là 2 tác phẩm của 2 nhà văn này là về thơ. Khác biệt với thể loại văn xuôi/viết so với các tác giả còn lại. Điều đó cho ta đầu mối rằng các tác phẩm có cùng một thể loại (văn xuối, hay thơ) thì nhận dạng tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Conclusions\n",
    "- Dữ liệu dạng text cần phải qua một quá trình tiền xử lý mới có thể sử dụng được. Quá trình này có thể tóm tắt như sau: Load dữ liệu -> những dữ liệu này có phải cùng loại (thơ và văn xuôi không xếp chung chẳng hạn) -> bỏ dấu, biến về chữ thường, loại bỏ stop word, tách ra từng đoạn, bỏ những đoạn quá ngắn -> vector hóa, nối vector hoặc np.mean tất cả các vector trong cùng môt đoạn -> bỏ vào mô hình.\n",
    "- Việc lập nên dataframe giúp ý tưởng trên nên rõ ràng hơn, đồng thời cũng mô tả được dữ liệu của ta như thế nào (liệu có imbalance không)\n",
    "- Mô hình liệu train bao nhiêu epoch thì dừng được (mới thử đến epochs thứ 30)? Những dữ liệu dạng text khi nào dùng cross validation thì phù hợp?\n",
    "- Nếu không dùng mô hình deeplearning, liệu ý tưởng dùng mô hình classification như random forest, logistic regression liệu có tốt hơn? Cũng như đỡ tốn 'tài nguyên' hơn?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
