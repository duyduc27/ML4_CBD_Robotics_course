{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Binary Classification Of Sonar Returns.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5vrvvjKmg8Yc","colab_type":"text"},"source":["## I. Baseline Neural Network Model Performance"]},{"cell_type":"markdown","metadata":{"id":"rn5ELqC2hIWR","colab_type":"text"},"source":["Đầu tiên vạch ra những kế hoạch ban đầu (baseline ) cho bài toán này. Chúng ta sẽ bắt đầu bằng việc import những class và function cần thiết."]},{"cell_type":"code","metadata":{"id":"ofRxGCRhe3Ji","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score, StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.pipeline import Pipeline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZCDJAKBihwD1","colab_type":"text"},"source":["Ta khởi tạo **random number generator** để bảo đảm rằng lúc nào ta cũng lấy được cùng một kết quả khi khai triển đoạn code này. Điều này cũng giúp khi chúng ta debug.<br>\n","Mở thử data từ bên ngoài, ta thấy có **60** biến input (X) và **1** biến output (Y)."]},{"cell_type":"code","metadata":{"id":"UDg9Y_lGYSMf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"outputId":"5ae59445-3e1e-4df5-e4a7-19836ce3bfa8","executionInfo":{"status":"ok","timestamp":1562203098237,"user_tz":-420,"elapsed":1258,"user":{"displayName":"Duc Le","photoUrl":"https://lh5.googleusercontent.com/-kFhcwMVab9I/AAAAAAAAAAI/AAAAAAAAAJk/XaIEYBqu6-g/s64/photo.jpg","userId":"06644460188222599869"}}},"source":["# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# load dataset\n","url = 'https://raw.githubusercontent.com/duyduc27/ML4_CBD_Robotics_course/master/study/Data%20files/sonar.csv'\n","dataframe = pd.read_csv(url, header=None)\n","dataset = dataframe.values\n","X = dataset[: , :60].astype(float) #input\n","Y = dataset[: , 60] #output\n","dataframe.head()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0200</td>\n","      <td>0.0371</td>\n","      <td>0.0428</td>\n","      <td>0.0207</td>\n","      <td>0.0954</td>\n","      <td>0.0986</td>\n","      <td>0.1539</td>\n","      <td>0.1601</td>\n","      <td>0.3109</td>\n","      <td>0.2111</td>\n","      <td>0.1609</td>\n","      <td>0.1582</td>\n","      <td>0.2238</td>\n","      <td>0.0645</td>\n","      <td>0.0660</td>\n","      <td>0.2273</td>\n","      <td>0.3100</td>\n","      <td>0.2999</td>\n","      <td>0.5078</td>\n","      <td>0.4797</td>\n","      <td>0.5783</td>\n","      <td>0.5071</td>\n","      <td>0.4328</td>\n","      <td>0.5550</td>\n","      <td>0.6711</td>\n","      <td>0.6415</td>\n","      <td>0.7104</td>\n","      <td>0.8080</td>\n","      <td>0.6791</td>\n","      <td>0.3857</td>\n","      <td>0.1307</td>\n","      <td>0.2604</td>\n","      <td>0.5121</td>\n","      <td>0.7547</td>\n","      <td>0.8537</td>\n","      <td>0.8507</td>\n","      <td>0.6692</td>\n","      <td>0.6097</td>\n","      <td>0.4943</td>\n","      <td>0.2744</td>\n","      <td>0.0510</td>\n","      <td>0.2834</td>\n","      <td>0.2825</td>\n","      <td>0.4256</td>\n","      <td>0.2641</td>\n","      <td>0.1386</td>\n","      <td>0.1051</td>\n","      <td>0.1343</td>\n","      <td>0.0383</td>\n","      <td>0.0324</td>\n","      <td>0.0232</td>\n","      <td>0.0027</td>\n","      <td>0.0065</td>\n","      <td>0.0159</td>\n","      <td>0.0072</td>\n","      <td>0.0167</td>\n","      <td>0.0180</td>\n","      <td>0.0084</td>\n","      <td>0.0090</td>\n","      <td>0.0032</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>0.4918</td>\n","      <td>0.6552</td>\n","      <td>0.6919</td>\n","      <td>0.7797</td>\n","      <td>0.7464</td>\n","      <td>0.9444</td>\n","      <td>1.0000</td>\n","      <td>0.8874</td>\n","      <td>0.8024</td>\n","      <td>0.7818</td>\n","      <td>0.5212</td>\n","      <td>0.4052</td>\n","      <td>0.3957</td>\n","      <td>0.3914</td>\n","      <td>0.3250</td>\n","      <td>0.3200</td>\n","      <td>0.3271</td>\n","      <td>0.2767</td>\n","      <td>0.4423</td>\n","      <td>0.2028</td>\n","      <td>0.3788</td>\n","      <td>0.2947</td>\n","      <td>0.1984</td>\n","      <td>0.2341</td>\n","      <td>0.1306</td>\n","      <td>0.4182</td>\n","      <td>0.3835</td>\n","      <td>0.1057</td>\n","      <td>0.1840</td>\n","      <td>0.1970</td>\n","      <td>0.1674</td>\n","      <td>0.0583</td>\n","      <td>0.1401</td>\n","      <td>0.1628</td>\n","      <td>0.0621</td>\n","      <td>0.0203</td>\n","      <td>0.0530</td>\n","      <td>0.0742</td>\n","      <td>0.0409</td>\n","      <td>0.0061</td>\n","      <td>0.0125</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>0.6333</td>\n","      <td>0.7060</td>\n","      <td>0.5544</td>\n","      <td>0.5320</td>\n","      <td>0.6479</td>\n","      <td>0.6931</td>\n","      <td>0.6759</td>\n","      <td>0.7551</td>\n","      <td>0.8929</td>\n","      <td>0.8619</td>\n","      <td>0.7974</td>\n","      <td>0.6737</td>\n","      <td>0.4293</td>\n","      <td>0.3648</td>\n","      <td>0.5331</td>\n","      <td>0.2413</td>\n","      <td>0.5070</td>\n","      <td>0.8533</td>\n","      <td>0.6036</td>\n","      <td>0.8514</td>\n","      <td>0.8512</td>\n","      <td>0.5045</td>\n","      <td>0.1862</td>\n","      <td>0.2709</td>\n","      <td>0.4232</td>\n","      <td>0.3043</td>\n","      <td>0.6116</td>\n","      <td>0.6756</td>\n","      <td>0.5375</td>\n","      <td>0.4719</td>\n","      <td>0.4647</td>\n","      <td>0.2587</td>\n","      <td>0.2129</td>\n","      <td>0.2222</td>\n","      <td>0.2111</td>\n","      <td>0.0176</td>\n","      <td>0.1348</td>\n","      <td>0.0744</td>\n","      <td>0.0130</td>\n","      <td>0.0106</td>\n","      <td>0.0033</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>0.0881</td>\n","      <td>0.1992</td>\n","      <td>0.0184</td>\n","      <td>0.2261</td>\n","      <td>0.1729</td>\n","      <td>0.2131</td>\n","      <td>0.0693</td>\n","      <td>0.2281</td>\n","      <td>0.4060</td>\n","      <td>0.3973</td>\n","      <td>0.2741</td>\n","      <td>0.3690</td>\n","      <td>0.5556</td>\n","      <td>0.4846</td>\n","      <td>0.3140</td>\n","      <td>0.5334</td>\n","      <td>0.5256</td>\n","      <td>0.2520</td>\n","      <td>0.2090</td>\n","      <td>0.3559</td>\n","      <td>0.6260</td>\n","      <td>0.7340</td>\n","      <td>0.6120</td>\n","      <td>0.3497</td>\n","      <td>0.3953</td>\n","      <td>0.3012</td>\n","      <td>0.5408</td>\n","      <td>0.8814</td>\n","      <td>0.9857</td>\n","      <td>0.9167</td>\n","      <td>0.6121</td>\n","      <td>0.5006</td>\n","      <td>0.3210</td>\n","      <td>0.3202</td>\n","      <td>0.4295</td>\n","      <td>0.3654</td>\n","      <td>0.2655</td>\n","      <td>0.1576</td>\n","      <td>0.0681</td>\n","      <td>0.0294</td>\n","      <td>0.0241</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>0.4152</td>\n","      <td>0.3952</td>\n","      <td>0.4256</td>\n","      <td>0.4135</td>\n","      <td>0.4528</td>\n","      <td>0.5326</td>\n","      <td>0.7306</td>\n","      <td>0.6193</td>\n","      <td>0.2032</td>\n","      <td>0.4636</td>\n","      <td>0.4148</td>\n","      <td>0.4292</td>\n","      <td>0.5730</td>\n","      <td>0.5399</td>\n","      <td>0.3161</td>\n","      <td>0.2285</td>\n","      <td>0.6995</td>\n","      <td>1.0000</td>\n","      <td>0.7262</td>\n","      <td>0.4724</td>\n","      <td>0.5103</td>\n","      <td>0.5459</td>\n","      <td>0.2881</td>\n","      <td>0.0981</td>\n","      <td>0.1951</td>\n","      <td>0.4181</td>\n","      <td>0.4604</td>\n","      <td>0.3217</td>\n","      <td>0.2828</td>\n","      <td>0.2430</td>\n","      <td>0.1979</td>\n","      <td>0.2444</td>\n","      <td>0.1847</td>\n","      <td>0.0841</td>\n","      <td>0.0692</td>\n","      <td>0.0528</td>\n","      <td>0.0357</td>\n","      <td>0.0085</td>\n","      <td>0.0230</td>\n","      <td>0.0046</td>\n","      <td>0.0156</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","      <td>R</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       0       1       2       3       4   ...      56      57      58      59  60\n","0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n","1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n","2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n","3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n","4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n","\n","[5 rows x 61 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"fkT1-oXBgujh","colab_type":"text"},"source":["Biến output có loại là string value ( 'M' - mine và 'R' - rock). Chúng ta phải convert sang các giá trị nguyên **0** và **1**. Chúng ta làm được qua class Label Enconder của Sklearn."]},{"cell_type":"code","metadata":{"id":"f-hOjxYUjCb5","colab_type":"code","colab":{}},"source":["# Encode class values as integers\n","encoder = LabelEncoder()\n","encoded_Y = encoder.fit_transform(Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHpwdJCjjRA-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"e6598b41-e33f-4dd4-e763-dcc698dc1b89","executionInfo":{"status":"ok","timestamp":1562203098265,"user_tz":-420,"elapsed":1229,"user":{"displayName":"Duc Le","photoUrl":"https://lh5.googleusercontent.com/-kFhcwMVab9I/AAAAAAAAAAI/AAAAAAAAAJk/XaIEYBqu6-g/s64/photo.jpg","userId":"06644460188222599869"}}},"source":["encoded_Y # sau khi label encode"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"47jFaMtPkDHw","colab_type":"text"},"source":["Giờ chúng ta đã sẵn sàng để tạo mô hình mạng nơ-ron sử dụng Keras. Chúng ta sẽ sử dụng Sklearn để đánh giá mô hình thông qua stratified k-fold cross-validation (StratifiedKFold). Kĩ thuật resampling này sẽ cung cấp sự đo lường cho biểu diễn của mô hình.<br>\n","Để sử dụng Keras với Sklearn, chúng ta phải sử dụng wrapper KerasClassifier. Class này nhận một hàm và trả lại mô hình mạng nơ-ron của chúng ta. Nó cũng lấy những thông số và mang theo qua việc gọi fit() như số lượng epoch và batch size.<br>\n","Hãy bắt đầu bằng việc định ra một function mà cái đó tạo ra baseline model của chúng ta. Mô hình của chúng ta sẽ có một hidden layer là fully connected layer với số nơ-ron bằng số input.<br>\n","Các weights được khởi tạo sử dụng một Gaussian random number nhỏ. Activation function ở đây là Rectifier. Cái output layer chứa chỉ một nơ-ron để tiên đoán. Nó sử dụng activation function là Sigmoid để tạo ra xác suất output trong range từ 0 đến 1. <br>\n","Cuối cùng, ta sử dụng logarithmic loss function (binary_crossentropy) trong khi train. Loss function này thì phù hợp cho bài toán phân loại nhị phân. Mô hình cũng sử dụng optimizer là Adam cho gradient descent và metrics là accuracy sẽ được thu thập khi mô hình được train."]},{"cell_type":"code","metadata":{"id":"f5okXxcrqQCr","colab_type":"code","colab":{}},"source":["#base line model\n","def create_baseline():\n","  # create model\n","  model = Sequential()\n","  model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n","  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","  # compile model\n","  model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NPQxXRGsHXT","colab_type":"text"},"source":["Giờ là lúc đánh giá mô hình qua việc sử dụng stratified cross-validation. Chúng ta đưa số lượng training epochs vào KerasClassifier. Phần Verbose output  bị tắt. (nếu mở sẽ hiện ra quá trình 10 lần cho 10-fold của cross validation)"]},{"cell_type":"code","metadata":{"id":"M9BsqAlBtKPX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":322},"outputId":"e13dae61-22b2-4b69-c1d3-f42438b1d05f","executionInfo":{"status":"ok","timestamp":1562205962142,"user_tz":-420,"elapsed":108120,"user":{"displayName":"Duc Le","photoUrl":"https://lh5.googleusercontent.com/-kFhcwMVab9I/AAAAAAAAAAI/AAAAAAAAAJk/XaIEYBqu6-g/s64/photo.jpg","userId":"06644460188222599869"}}},"source":["# evaluate model with standardized dataset\n","estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0 )\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n","print('Baseline %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0704 02:04:17.807852 140218976675712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0704 02:04:17.853160 140218976675712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0704 02:04:17.861752 140218976675712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","W0704 02:04:17.890213 140218976675712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0704 02:04:17.912739 140218976675712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0704 02:04:17.919286 140218976675712 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0704 02:04:18.124001 140218976675712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Baseline 80.28% (7.52%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sEfS4g_hvuQf","colab_type":"text"},"source":["Mô hình có độ chính xác trung bình  là 80.28% và giao động ở mức 7.52%"]},{"cell_type":"markdown","metadata":{"id":"Z-pBzwizwLeU","colab_type":"text"},"source":["## II.Improve Performance With Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"OB4OriT4w7dt","colab_type":"text"},"source":["Sẽ là rất thiết thực nếu bạn chuẩn bị lại dữ liệu trước khi lên mô hình. Mô hình mạng nơ-ron thì _đặc biệt phù hợp_ với khi có những giá trị **input nhất quán**. Việc cách hiệu quả cho việc phối hợp một bộ dữ liệu dạng bảng khi xây dựng một mô hình mạng nơ-ron là chuẩn hóa dữ liệu (standardization). Ở đây dữ liệu sẽ được tỷ lệ lại với giá trị mean trên từng attribute bằng **0** và std bằng **1**. Điều này hợp với các phân phối Gaussian và giống Gaussian trong việc chuẩn hóa lại trọng tâm khuynh hướng của từng attribute."]},{"cell_type":"code","metadata":{"id":"2aXzvzRqz1Mj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8adebf74-4542-4ca6-92de-ed870fbb6175","executionInfo":{"status":"ok","timestamp":1562208273300,"user_tz":-420,"elapsed":114447,"user":{"displayName":"Duc Le","photoUrl":"https://lh5.googleusercontent.com/-kFhcwMVab9I/AAAAAAAAAAI/AAAAAAAAAJk/XaIEYBqu6-g/s64/photo.jpg","userId":"06644460188222599869"}}},"source":["# Binary Classification with Sonar Dataset: Standardized\n","import numpy as np\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score, StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.pipeline import Pipeline\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","# load dataset\n","url = 'https://raw.githubusercontent.com/duyduc27/ML4_CBD_Robotics_course/master/study/Data%20files/sonar.csv'\n","dataframe = pd.read_csv(url, header=None)\n","dataset = dataframe.values\n","# split into input (X) and output (Y) variables\n","X = dataset[:, :60].astype(float) #input\n","Y = dataset[:, 60] #output\n","# encode class values as integers\n","encoder = LabelEncoder()\n","encoded_Y = encoder.fit_transform(Y)\n","# baseline model\n","def create_baseline():\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n","  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","  # compile model\n","  model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n","  return model\n","\n","# evaluate baseline model with standardized dataset <-- KHÁC BIỆT Ở ĐÂY\n","estimator = []\n","estimator.append(('standardize', StandardScaler())) # <-- The difference HERE\n","estimator.append(('MultiLayer Perceptrons', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n","pipeline = Pipeline(estimator)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n","print('Standardized: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Standardized: 84.11% (4.36%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2igLEP7x4eYb","colab_type":"text"},"source":["Chúng ta chỉ thay đổi rất nhỏ là chuẩn hóa lại dữ liệu, nhưng kết quả nâng lên rất tốt từ 80 lên 84% !"]},{"cell_type":"markdown","metadata":{"id":"o8P9N-CK4uxe","colab_type":"text"},"source":["## III. Tuning Layers and Neurons in The Model\n","Có nhiều thứ để tune trong một mạng nơ-ron như là weight khởi tạo, activation functions, optimizer, vâng vâng. Ở trong phần này ta sẽ đi qua hai trải nghiệm trên cấu trúc của mạng này là: làm nó _nhỏ đi_ và làm nó  _lớn hơn_."]},{"cell_type":"markdown","metadata":{"id":"moe0BFYl7qJr","colab_type":"text"},"source":["### 3.1 Evaluate a Smaller Network"]},{"cell_type":"markdown","metadata":{"id":"dgYSxP-aBtKe","colab_type":"text"},"source":["Câu hỏi đặt ra ở đây: Tôi nghi ngờ rằng có nhiều biến input dư thừa cho bài toán này. Mô tả dữ liệu cho thấy nó có cùng tín hiệu ở các góc khác nhau. Có lẽ, có nhiều góc thì liên quan hơn những cái còn lại. Chúng ta có thể tập trung vào những loại feature quan trọng này trong mạng bằng việc **giới hạn** khoảng không của hidden layer đầu tiên.<br>\n","Ở trải nghiệm này chúng ta sẽ sử dụng lại baseline model nhưng chỉ với 30 nơ-ron ở hidden layer đầu tiên thay vì 60 như ban đầu. Điều này sẽ đẩy áp lực lên mạng trong quá trình train để chọn ra những cấu trúc quan trọng nhất ở đầu vào (input) của mô hình. Và chúng ta cũng sẽ chuẩn hóa dữ liệu như ở ví dụ trước để có thêm lợi thế.<br>\n","Ví dụ bên dưới đơn thuần chỉ thay đổi số nơ-ron ở lớp hidden layer đầu tiên, các biến được giữ nguyên và sử dụng lại ở ví dụ trên, để xem sự thay đổi."]},{"cell_type":"code","metadata":{"id":"xwSxDh0v8gc5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"23c9b0bf-061f-4636-dadb-0187dc2a67bc","executionInfo":{"status":"ok","timestamp":1562210567604,"user_tz":-420,"elapsed":124654,"user":{"displayName":"Duc Le","photoUrl":"https://lh5.googleusercontent.com/-kFhcwMVab9I/AAAAAAAAAAI/AAAAAAAAAJk/XaIEYBqu6-g/s64/photo.jpg","userId":"06644460188222599869"}}},"source":["# Binary Classification with Sonar Dataset: Standardized Smaller\n","\n","# smaller model\n","def create_smaller():\n","  # create model\n","  model = Sequential()\n","  model.add(Dense(30, input_dim=60, kernel_initializer='normal', activation='relu'))  # <- reduce neurons into 30\n","  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","  # compile model\n","  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model\n","\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size =5, verbose=0)))\n","pipeline = Pipeline(estimators)\n","\n","results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n","print('Smaller: %.2f%% (%.2f%%)' % ( results.mean()*100, results.std()*100))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Smaller: 85.52% (5.85%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"azdWNTf5DY5D","colab_type":"text"},"source":["Vậy là sau khi giảm số nơ-ron , độ chính xác của mô hình đã tăng thêm được một chút!"]},{"cell_type":"markdown","metadata":{"id":"1bPx5Y8dFKLt","colab_type":"text"},"source":["### 3.2 Evaluate a Larger Network"]},{"cell_type":"markdown","metadata":{"id":"IQGFgtFMMLj3","colab_type":"text"},"source":["Một mạng nơ-ron với nhiều layer hơn thường có nhiều cơ hội để mạng này nhả ra được những feature trọng yếu và nối lại chúng theo các cách phi tuyến tính hữu ích. Chúng ta có thể thêm nhiều layer hơn vào mạng để xem thử sự cải thiện.<br>\n","Ở ví dụ này, ta thêm 1 hidden layer mới sau hidden layer đầu tiên, và layer mới này có 30 nơ-ron.<br>\n","Ý tưởng ở đây là cho mạng của chúng ta thêm cơ hội mô hình tất cả các biến trước khi bị 'nén cổ chai' và bị ép vào khuôn khổ giới hạn, giống như chúng ta đã làm với ví dụ ở trên - là làm nhỏ mạng đi."]},{"cell_type":"code","metadata":{"id":"Dpz0SBBgHVnP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1de5013a-462b-4bac-c24c-14bc3891856d","executionInfo":{"status":"ok","timestamp":1562213350247,"user_tz":-420,"elapsed":151583,"user":{"displayName":"Duc Le","photoUrl":"https://lh5.googleusercontent.com/-kFhcwMVab9I/AAAAAAAAAAI/AAAAAAAAAJk/XaIEYBqu6-g/s64/photo.jpg","userId":"06644460188222599869"}}},"source":["# larger model\n","def create_larger():\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n","  model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n","  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","  # compile model\n","  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model\n","\n","estimators = []\n","estimators.append(('Standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n","pipeline = Pipeline(estimators)\n","\n","results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n","print('Larger: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Larger: 84.57% (5.24%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4zO2cOq0LGsa","colab_type":"text"},"source":["Trong ví dụ này chúng ta có thể thấy rằng độ biểu diễn của mô hình không tăng lên thêm. Điều này có thể do số nhiễu do việc train này. <br>\n","Xa hơn nữa là việc điều chỉnh optimizer, số lần train epochs . Chúng được mong đợi là có thể cải thiện thêm cho mô hình."]}]}